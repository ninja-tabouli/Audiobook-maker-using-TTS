{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nijad/.pyenv/versions/3.8.10/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import PyPDF2\n",
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize file and path\n",
    "pdf_filename = 'name'\n",
    "pdf_path = os.path.expanduser(f'~/audiobooks/{pdf_filename}')\n",
    "input_dir = os.path.expanduser('~/audiobooks/')\n",
    "output_dir = os.path.expanduser('~/audiobooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      " > tts_models/en/vctk/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n"
     ]
    }
   ],
   "source": [
    "# Initialize TTS engine\n",
    "model_name = TTS.list_models()[17]\n",
    "tts = TTS(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store audio and text segments\n",
    "audio_segments = []\n",
    "cleaned_text_segments = []\n",
    "merged_text = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the PDF\n",
    "with open(pdf_path, \"rb\") as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "\n",
    "    # Loop through pages and convert text to speech\n",
    "    for num in range(num_pages):\n",
    "        try:\n",
    "            page = pdf_reader.pages[num]\n",
    "            text1 = page.extract_text()\n",
    "\n",
    "            if not text1.strip():\n",
    "                continue\n",
    "\n",
    "            # Remove commas and periods from the extracted text\n",
    "            cleaned_text = text1.replace(',', '').replace('.', '')\n",
    "\n",
    "            # Append the cleaned text to the list of segments\n",
    "            cleaned_text_segments.append(cleaned_text)\n",
    "\n",
    "            # Join the cleaned text segments into a single string\n",
    "            merged_text = ' '.join(cleaned_text_segments)\n",
    "\n",
    "            audio_filename = f'page_{num + 1}.wav'\n",
    "            audio_path = os.path.join(output_dir, audio_filename)\n",
    "            tts.tts_to_file(text=merged_text, speaker=tts.speakers[0], file_path=audio_path, speed=1.5, emotion=\"Happy\")\n",
    "\n",
    "            # Load the audio segment and append to the list\n",
    "            audio_segment = AudioSegment.from_wav(audio_path)\n",
    "            audio_segments.append(audio_segment)\n",
    "\n",
    "            # Clear the lists for the next iteration\n",
    "            cleaned_text_segments.clear()\n",
    "            audio_segments.clear()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "            print(\"Restarting loop from the last index where the error occurred.\")\n",
    "            continue  # Restart the loop from the last index where the error occurred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged audio saved to '/home/nijad/audiobooks/merged_audio.wav'.\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all WAV files in the input directory\n",
    "wav_files = [f for f in os.listdir(input_dir) if f.startswith('page_') and f.endswith('.wav')]\n",
    "\n",
    "# Sort the WAV files based on the page numbers in their filenames\n",
    "sorted_wav_files = sorted(wav_files, key=lambda f: int(f.split('_')[1].split('.')[0]))\n",
    "\n",
    "# Load and append audio segments in the sorted order\n",
    "for wav_file in sorted_wav_files:\n",
    "    wav_path = os.path.join(input_dir, wav_file)\n",
    "    audio_segment = AudioSegment.from_wav(wav_path)\n",
    "    audio_segments.append(audio_segment)\n",
    "\n",
    "# Concatenate audio segments into a single audio file\n",
    "merged_audio = AudioSegment.empty()\n",
    "for segment in audio_segments:\n",
    "    merged_audio += segment\n",
    "\n",
    "# Save the merged audio to a file\n",
    "merged_audio_filename = 'merged_audio.wav'\n",
    "merged_audio_path = os.path.join(output_dir, merged_audio_filename)\n",
    "merged_audio.export(merged_audio_path, format='wav')\n",
    "\n",
    "print(f\"Merged audio saved to '{merged_audio_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
